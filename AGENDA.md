# Data Engineering - Projekt Agenda & Abgabe

**Projekt:** Amazon Arbitrage Tracker
**Student:** Samuel
**Fach:** Data Engineering WS2025
**Letztes Update:** 2026-01-08

---

## ðŸ“‹ PrÃ¼fungsleistung - Anforderungen

### ðŸŽ¯ **Projektziel**
Entwicklung einer **End-to-End-LÃ¶sung** zur Erfassung, Verarbeitung und Speicherung von Daten, inklusive Beispielanalyse.

---

## ðŸ—ï¸ **Die 3 SÃ¤ulen des Projekts**

### **1. Scraping/Data Ingestion** âœ…
- âœ… Daten mÃ¼ssen **periodisch** abgegriffen werden
- âš ï¸ Scheduling idealerweise mit **Airflow** (oder Ã¤hnlich)
- **Mein Projekt:** Keepa API mit periodischem Polling (alle 5min)

### **2. Vorverarbeitung der Daten** âœ…
- âœ… **Externe und umfangreiche** Vorverarbeitung
- **Mein Projekt:**
  - Enrichment Consumer (Keepa â†’ normalisiert)
  - Arbitrage Detector (Margin-Berechnung)

### **3. Speicherung der Daten** âœ…
- âœ… Speicherung in **sinnvoller Datenbank** fÃ¼r den Use Case
- âœ… **Einstellung und Optimierung** der Datenbank
- âœ… **Sinnvolles Deployment** mit entsprechenden Einstellungen
- **Mein Projekt:** Elasticsearch + Kafka

---

## ðŸ“Š **ZusÃ¤tzliche Anforderungen**

### **Analyseteil** (nicht Data Engineering Kern, aber gefordert):
- âœ… FÃ¼hre **Analysen** auf den verarbeiteten Daten durch
- **Optionen:**
  - Klassischer Analytics Use Case âœ… (mein Arbitrage Detection)
  - Such-Optimierung
  - Verarbeitung von Echtzeitdaten âœ… (Kafka Streaming)

---

## ðŸ“… **Ablauf & Termine**

| Phase | Deadline | Status | Aktion |
|-------|----------|--------|--------|
| **Projektidee einreichen** | Ende Dezember 2025 | âš ï¸ ÃœBERFÃ„LLIG? | Dozent kontaktieren! |
| **Freigabe** | Nach PrÃ¼fung durch Projektleitung | â³ Warten | - |
| **Bearbeitungszeit** | Bis finaler PrÃ¤sentationstermin (tbd) | ðŸ”„ LÃ¤uft | Weiterarbeiten |
| **AbschlussprÃ¤sentation** | tbd (wird noch bekannt gegeben) | â³ Pending | Vorbereiten |

---

## ðŸ“¦ **Abgabe & Bewertung - Komponenten**

### **1. AbschlussprÃ¤sentation** ðŸŽ¤
- **Darstellung der getroffenen Entscheidungen**
- Warum Kafka? Warum Elasticsearch? Warum diese Architektur?
- Demo des Systems
- **TODO:** PrÃ¤sentation vorbereiten (PowerPoint/Slides)

### **2. Code-Abgabe** ðŸ’»
- âœ… Muss in **zugÃ¤nglichem Git Repository** vorliegen
- âœ… VollstÃ¤ndiger Source Code
- **Status:** âœ… Alles schon in Git (arbitrage-tracker/)

### **3. Einstellungen und Deployment** âš™ï¸
- âœ… **Alle Datenbank- und Deployment-Einstellungen als Code** verfÃ¼gbar
- âœ… z.B. Skripte, docker-compose.yml, Elasticsearch mappings
- âŒ **Keine manuellen Ã„nderungen** (z.B. via Kibana)
- **Status:**
  - âœ… docker-compose.yml vorhanden
  - âœ… ES Schema in docs/ definiert
  - âœ… Kafka Topics: via init-topics Service
  - âš ï¸ Airflow fehlt noch (kÃ¶nnte kritisch sein!)

---

## âœ… **Status Check - Was ich schon habe**

| Komponente | Status | Details |
|------------|--------|---------|
| **Data Ingestion** | âœ… Complete | Producer (Keepa API) |
| **Periodisches Scraping** | âœ… Complete | Polling alle 5min |
| **Scheduling Tool** | âŒ Missing | âš ï¸ Sollte Airflow sein! |
| **Vorverarbeitung** | âœ… Complete | Enrichment + Arbitrage |
| **Datenbank** | âœ… Complete | Elasticsearch optimiert |
| **Message Queue** | âœ… Complete | Kafka mit 3 Topics |
| **Deployment** | âœ… Complete | docker-compose.yml |
| **Code Repository** | âœ… Complete | Git vorhanden |
| **Analyseteil** | âœ… Complete | Arbitrage Detection |
| **Echtzeitdaten** | âœ… Complete | Kafka Streaming |
| **Tests** | âš ï¸ Partial | Nur 3 Unit Tests |
| **Dokumentation** | âš ï¸ Partial | Basis vorhanden |

---

## ðŸ”´ **KRITISCHE TODOs (Sofort erledigen!)**

### **1. Projektidee offiziell einreichen** ðŸš¨
- **Deadline:** Ende Dezember (mÃ¶glicherweise schon vorbei!)
- **Action:**
  - [ ] Dozent per E-Mail kontaktieren
  - [ ] Projektbeschreibung einreichen
  - [ ] Freigabe einholen
- **PrioritÃ¤t:** HÃ–CHSTE

### **2. Airflow/Scheduling Tool hinzufÃ¼gen** ðŸš¨
- **Warum:** Folien sagen explizit "idealerweise mit Airflow"
- **Aktuell:** Producer lÃ¤uft als Docker Service (suboptimal)
- **Action:**
  - [ ] Airflow zu docker-compose.yml hinzufÃ¼gen
  - [ ] DAG erstellen fÃ¼r periodisches Scraping
  - [ ] Producer-Logik in Airflow Task migrieren
- **PrioritÃ¤t:** SEHR HOCH
- **GeschÃ¤tzte Zeit:** 4-6 Stunden

---

## ðŸŸ¡ **WICHTIGE TODOs (Diese Woche)**

### **3. Tests erweitern**
- **Aktuell:** Nur 3 Unit Tests
- **Ziel:** Mindestens 50% Coverage
- **Action:**
  - [ ] Unit Tests fÃ¼r alle Worker
  - [ ] Integration Tests (Kafka â†’ ES)
  - [ ] E2E Test (kompletter Flow)
- **PrioritÃ¤t:** HOCH
- **GeschÃ¤tzte Zeit:** 6-8 Stunden

### **4. Deployment-Dokumentation**
- **Aktuell:** README vorhanden, aber nicht detailliert genug
- **Action:**
  - [ ] DEPLOYMENT.md erstellen
  - [ ] Alle Einstellungen dokumentieren
  - [ ] Schritt-fÃ¼r-Schritt Anleitung
  - [ ] Troubleshooting Guide
- **PrioritÃ¤t:** HOCH
- **GeschÃ¤tzte Zeit:** 2-3 Stunden

### **5. PrÃ¤sentation vorbereiten**
- **FÃ¼r:** AbschlussprÃ¤sentation
- **Action:**
  - [ ] Architektur-Diagramm erstellen
  - [ ] EntscheidungsbegrÃ¼ndungen dokumentieren
  - [ ] Live-Demo vorbereiten
  - [ ] PowerPoint/Slides erstellen
- **PrioritÃ¤t:** MITTEL-HOCH
- **GeschÃ¤tzte Zeit:** 4-6 Stunden

---

## ðŸŸ¢ **OPTIONALE TODOs (Nice to have)**

### **6. Code Quality verbessern**
- [ ] Linting (flake8/ruff) ausfÃ¼hren
- [ ] Type Hints Ã¼berprÃ¼fen (mypy)
- [ ] Code Complexity messen
- [ ] Docstrings vervollstÃ¤ndigen
- **GeschÃ¤tzte Zeit:** 3-4 Stunden

### **7. Monitoring hinzufÃ¼gen**
- [ ] Prometheus Metriken
- [ ] Grafana Dashboard
- [ ] Alerting bei Fehlern
- **GeschÃ¤tzte Zeit:** 6-8 Stunden

### **8. Performance Optimierung**
- [ ] Elasticsearch Query-Optimierung
- [ ] Kafka Tuning
- [ ] Caching-Layer (Redis?)
- **GeschÃ¤tzte Zeit:** 4-6 Stunden

---

## ðŸ“Š **Aktueller Projekt-Score**

| Anforderung | Status | Score | Gewichtung |
|-------------|--------|-------|------------|
| Data Ingestion | âœ… Complete | 100% | 15% |
| Periodisches Scraping | âœ… Complete | 100% | 10% |
| Scheduling Tool (Airflow) | âŒ Missing | 0% | 15% âš ï¸ |
| Vorverarbeitung | âœ… Complete | 100% | 15% |
| Datenbank-Setup | âœ… Complete | 100% | 15% |
| Deployment as Code | âœ… Complete | 90% | 10% |
| Git Repository | âœ… Complete | 100% | 5% |
| Analyseteil | âœ… Complete | 100% | 10% |
| Tests | âš ï¸ Partial | 30% | 5% |
| Dokumentation | âš ï¸ Partial | 70% | 5% |
| **GESAMT** | | **~78%** | |

**EinschÃ¤tzung:** Mit Airflow â†’ ~93%+ mÃ¶glich! ðŸŽ¯

---

## ðŸŽ¯ **Priorisierter Wochenplan**

### **Woche 1 (Diese Woche):**
**Montag-Dienstag:**
- [ ] Dozent kontaktieren (Projektidee einreichen)
- [ ] Docker zum Laufen bringen
- [ ] System testen mit Test-Daten

**Mittwoch-Donnerstag:**
- [ ] Airflow hinzufÃ¼gen
- [ ] DAG fÃ¼r Scraping erstellen
- [ ] Producer in Airflow migrieren

**Freitag-Sonntag:**
- [ ] Tests schreiben (Ziel: 50% Coverage)
- [ ] DEPLOYMENT.md erstellen

### **Woche 2:**
**Montag-Mittwoch:**
- [ ] Code aufrÃ¤umen (Linting, Types)
- [ ] Dokumentation vervollstÃ¤ndigen

**Donnerstag-Sonntag:**
- [ ] PrÃ¤sentation erstellen
- [ ] Live-Demo vorbereiten
- [ ] Architektur-Diagramme

---

## ðŸ“‹ **PrÃ¤sentations-Vorbereitung**

### **Folien-Struktur (Vorschlag):**

**1. Intro (2 Min)**
- Projektziel
- Business Case (Arbitrage-Opportunities)

**2. Architektur (5 Min)**
- Architektur-Diagramm
- Komponenten-Ãœbersicht
- Datenfluss

**3. Technische Entscheidungen (5 Min)**
- **Warum Kafka?**
  - Event-driven Architecture
  - Entkopplung der Services
  - At-least-once Garantien
- **Warum Elasticsearch?**
  - Full-text Search
  - Aggregationen fÃ¼r Analytics
  - Real-time Indexing
- **Warum Docker Compose?**
  - Reproduzierbares Environment
  - Easy Deployment
  - Service Orchestration

**4. Implementierung (5 Min)**
- 5 Worker (Producer, Consumer, Arbitrage, API, Dashboard)
- 4000+ LOC
- Poetry fÃ¼r Dependencies
- Kafka Topics & Message Flow

**5. Demo (5 Min)**
- Live-System zeigen
- Dashboard mit Opportunities
- Kibana (ES Queries)
- Kafka Topics anschauen

**6. Learnings & Ausblick (3 Min)**
- Was gut lief
- Herausforderungen
- MÃ¶gliche Erweiterungen

**Total: ~25 Min + 5 Min Fragen**

---

## ðŸŽ“ **EntscheidungsbegrÃ¼ndungen (fÃ¼r PrÃ¤sentation)**

### **Architektur-Entscheidungen:**

**1. Microservices statt Monolith**
- **Warum:** Separation of Concerns, unabhÃ¤ngige Skalierung
- **Vorteil:** Jeder Worker kann separat entwickelt/deployed werden

**2. Event-Driven Architecture (Kafka)**
- **Warum:** Asynchrone Verarbeitung, Resilienz
- **Vorteil:** Services mÃ¼ssen nicht online sein, Messages werden gepuffert

**3. Elasticsearch als Datenbank**
- **Warum:** Such-Anforderungen, Aggregationen, Real-time
- **Alternative:** PostgreSQL wÃ¤re zu langsam fÃ¼r Full-text Search

**4. Docker Compose statt Kubernetes**
- **Warum:** Einfacheres Setup, ausreichend fÃ¼r Projekt-Scope
- **Trade-off:** Weniger Production-ready, aber fÃ¼r Uni-Projekt okay

**5. Poetry statt pip**
- **Warum:** Besseres Dependency Management, Lock-Files
- **Vorteil:** Reproduzierbare Builds

---

## ðŸ“ž **Kontakte & Ressourcen**

### **Dozent:**
- **Name:** [TODO: Namen eintragen]
- **E-Mail:** [TODO: E-Mail eintragen]
- **Sprechstunde:** [TODO: Zeiten eintragen]

### **NÃ¼tzliche Links:**
- **Kafka Docs:** https://kafka.apache.org/documentation/
- **Elasticsearch Docs:** https://www.elastic.co/guide/en/elasticsearch/reference/current/index.html
- **Airflow Docs:** https://airflow.apache.org/docs/
- **Docker Compose:** https://docs.docker.com/compose/

### **Projekt-Repositories:**
- **Main Repo:** ~/Dokumente/WS2025/DataEnge/arbitrage-tracker/
- **Dokumentation:** ~/Dokumente/WS2025/DataEnge/arbitrage-tracker/MultiAgentDokumentation/

---

## â° **Zeitplan bis Abgabe**

### **Kritischer Pfad:**
```
Heute (Tag 0):
â””â”€> Dozent kontaktieren âœ‰ï¸
    â””â”€> Docker zum Laufen bringen ðŸ³
        â””â”€> System testen âœ…
            (2-3 Stunden)

Tag 1-2:
â””â”€> Airflow hinzufÃ¼gen ðŸ”„
    â””â”€> DAG erstellen
        â””â”€> Testen
            (8-10 Stunden)

Tag 3-4:
â””â”€> Tests schreiben ðŸ§ª
    â””â”€> DEPLOYMENT.md
        (8-10 Stunden)

Tag 5-7:
â””â”€> PrÃ¤sentation erstellen ðŸ“Š
    â””â”€> Demo vorbereiten
        â””â”€> Ãœben!
            (10-12 Stunden)

GESAMT: ~30-35 Stunden Arbeit
```

---

## ðŸš¨ **Risikoanalyse**

| Risiko | Wahrscheinlichkeit | Impact | Mitigation |
|--------|-------------------|--------|------------|
| Projektidee nicht genehmigt | Mittel | Hoch | FrÃ¼h beim Dozent melden |
| Airflow Integration schwierig | Mittel | Mittel | Tutorials nutzen, einfach halten |
| Docker startet nicht | Gering | Hoch | Bereits gelÃ¶st âœ… |
| Zeit reicht nicht | Mittel | Hoch | Priorisieren: Airflow > Tests > Rest |
| Demo schlÃ¤gt fehl | Gering | Hoch | Mehrfach testen, Backup-Plan |

---

## âœ… **Definition of Done (fÃ¼r Abgabe)**

**Das Projekt ist abgabebereit wenn:**

- [ ] Projektidee vom Dozent genehmigt
- [ ] Alle 3 SÃ¤ulen implementiert (Scraping, Vorverarbeitung, Speicherung)
- [ ] Airflow fÃ¼r Scheduling integriert
- [ ] Mindestens 50% Test Coverage
- [ ] DEPLOYMENT.md vollstÃ¤ndig
- [ ] Code in Git Repository
- [ ] docker-compose.yml funktioniert einwandfrei
- [ ] Alle Einstellungen als Code (keine manuellen Ã„nderungen)
- [ ] PrÃ¤sentation vorbereitet (Slides + Demo)
- [ ] System lÃ¤uft stabil fÃ¼r Demo

---

## ðŸ“ **Notizen & offene Fragen**

### **Fragen an Dozent:**
- [ ] Ist Projektidee noch rechtzeitig? (Deadline war Ende Dez)
- [ ] Ist Airflow Pflicht oder "idealerweise"?
- [ ] Wann ist der PrÃ¤sentationstermin?
- [ ] Wie lange soll die PrÃ¤sentation sein?
- [ ] Git Repository: Privat oder Public?

### **Technische Fragen:**
- [ ] Keepa API Key: Kostenlos oder bezahlt?
- [ ] Wie viele Test-ASINs fÃ¼r Demo?
- [ ] Soll System 24/7 laufen fÃ¼r Demo?

---

## ðŸŽ¯ **Erfolgs-Kriterien**

**Projekt ist erfolgreich wenn:**
- âœ… Note >= 1.7 (Ziel: 1.3 oder besser)
- âœ… System lÃ¤uft stabil
- âœ… Demo Ã¼berzeugt
- âœ… Alle Anforderungen erfÃ¼llt
- âœ… Gelernt: Kafka, Elasticsearch, Docker, Microservices

---

## ðŸ”„ **Version History**

| Datum | Version | Ã„nderungen |
|-------|---------|------------|
| 2026-01-08 | 1.0 | Initial Agenda erstellt |

---

**Letztes Update:** 2026-01-08 18:00
**NÃ¤chstes Review:** Nach Dozenten-Feedback
**Status:** ðŸŸ¡ In Progress - Kritische TODOs pending
